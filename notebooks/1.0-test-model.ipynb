{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models\n",
    "\n",
    "There are many different algorithms that can be used for classification problems. In this work, we aim to compare results by some of the main algorithms and evaluate the impact of our features treatment in each of them.\n",
    "\n",
    "### Objectives\n",
    "1. Evaluate different algorithms in terms of accuracy\n",
    "2. Evaluate the impact of data categorization in algorithms\n",
    "\n",
    "#### Tested Algorithms \n",
    "1. Linear Regression\n",
    "2. Gaussian Naive Bayes\n",
    "3. KNN Classifier\n",
    "4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/interim/train.csv')\n",
    "df_test = pd.read_csv('../data/interim/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked\n",
      "0             0       3    0  22.0      1      0    7.2500         0\n",
      "1             1       1    1  38.0      1      0   71.2833         2\n",
      "2             2       3    1  26.0      0      0    7.9250         0\n",
      "3             3       1    1  35.0      1      0   53.1000         0\n",
      "4             4       3    0  35.0      0      0    8.0500         0\n",
      "5             5       3    0   NaN      0      0    8.4583         1\n",
      "6             6       1    0  54.0      0      0   51.8625         0\n",
      "7             7       3    0   2.0      3      1   21.0750         0\n",
      "8             8       3    1  27.0      0      2   11.1333         0\n",
      "9             9       2    1  14.0      1      0   30.0708         2\n",
      "10           10       3    1   4.0      1      1   16.7000         0\n",
      "11           11       1    1  58.0      0      0   26.5500         0\n",
      "12           12       3    0  20.0      0      0    8.0500         0\n",
      "13           13       3    0  39.0      1      5   31.2750         0\n",
      "14           14       3    1  14.0      0      0    7.8542         0\n",
      "15           15       2    1  55.0      0      0   16.0000         0\n",
      "16           16       3    0   2.0      4      1   29.1250         1\n",
      "17           17       2    0   NaN      0      0   13.0000         0\n",
      "18           18       3    1  31.0      1      0   18.0000         0\n",
      "19           19       3    1   NaN      0      0    7.2250         2\n",
      "20           20       2    0  35.0      0      0   26.0000         0\n",
      "21           21       2    0  34.0      0      0   13.0000         0\n",
      "22           22       3    1  15.0      0      0    8.0292         1\n",
      "23           23       1    0  28.0      0      0   35.5000         0\n",
      "24           24       3    1   8.0      3      1   21.0750         0\n",
      "25           25       3    1  38.0      1      5   31.3875         0\n",
      "26           26       3    0   NaN      0      0    7.2250         2\n",
      "27           27       1    0  19.0      3      2  263.0000         0\n",
      "28           28       3    1   NaN      0      0    7.8792         1\n",
      "29           29       3    0   NaN      0      0    7.8958         0\n",
      "..          ...     ...  ...   ...    ...    ...       ...       ...\n",
      "861         861       2    0  21.0      1      0   11.5000         0\n",
      "862         862       1    1  48.0      0      0   25.9292         0\n",
      "863         863       3    1   NaN      8      2   69.5500         0\n",
      "864         864       2    0  24.0      0      0   13.0000         0\n",
      "865         865       2    1  42.0      0      0   13.0000         0\n",
      "866         866       2    1  27.0      1      0   13.8583         2\n",
      "867         867       1    0  31.0      0      0   50.4958         0\n",
      "868         868       3    0   NaN      0      0    9.5000         0\n",
      "869         869       3    0   4.0      1      1   11.1333         0\n",
      "870         870       3    0  26.0      0      0    7.8958         0\n",
      "871         871       1    1  47.0      1      1   52.5542         0\n",
      "872         872       1    0  33.0      0      0    5.0000         0\n",
      "873         873       3    0  47.0      0      0    9.0000         0\n",
      "874         874       2    1  28.0      1      0   24.0000         2\n",
      "875         875       3    1  15.0      0      0    7.2250         2\n",
      "876         876       3    0  20.0      0      0    9.8458         0\n",
      "877         877       3    0  19.0      0      0    7.8958         0\n",
      "878         878       3    0   NaN      0      0    7.8958         0\n",
      "879         879       1    1  56.0      0      1   83.1583         2\n",
      "880         880       2    1  25.0      0      1   26.0000         0\n",
      "881         881       3    0  33.0      0      0    7.8958         0\n",
      "882         882       3    1  22.0      0      0   10.5167         0\n",
      "883         883       2    0  28.0      0      0   10.5000         0\n",
      "884         884       3    0  25.0      0      0    7.0500         0\n",
      "885         885       3    1  39.0      0      5   29.1250         1\n",
      "886         886       2    0  27.0      0      0   13.0000         0\n",
      "887         887       1    1  19.0      0      0   30.0000         0\n",
      "888         888       3    1   NaN      1      2   23.4500         0\n",
      "889         889       1    0  26.0      0      0   30.0000         2\n",
      "890         890       3    0  32.0      0      0    7.7500         1\n",
      "\n",
      "[891 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "Y_train = df_train['Survived']\n",
    "\n",
    "X_test = df_test.drop('PassengerId', axis=1)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms with partially categorized features\n",
    "Our first batch of tests will input datasets without full categorization. After that, we'll compare results with and without categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39777264019086606"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train,Y_train)\n",
    "prd = linear_regressor.predict(X_test)\n",
    "\n",
    "linear_regressor.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792368125701459"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_regressor = GaussianNB()\n",
    "nb_regressor.fit(X_train,Y_train)\n",
    "prd = nb_regressor.predict(X_test)\n",
    "\n",
    "nb_regressor.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8069584736251403"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,Y_train)\n",
    "prd = knn.predict(X_test)\n",
    "\n",
    "knn.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842873176206509"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor = RandomForestClassifier(n_estimators=10)\n",
    "rf_regressor.fit(X_train,Y_train)\n",
    "prd = rf_regressor.predict(X_test)\n",
    "\n",
    "rf_regressor.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms with totally categorized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train,Y_train)\n",
    "prd = linear_regressor.predict(X_test)\n",
    "\n",
    "linear_regressor.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_regressor = GaussianNB()\n",
    "nb_regressor.fit(X_train,Y_train)\n",
    "prd = nb_regressor.predict(X_test)\n",
    "\n",
    "nb_regressor.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,Y_train)\n",
    "prd = knn.predict(X_test)\n",
    "\n",
    "knn.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestClassifier(n_estimators=10)\n",
    "rf_regressor.fit(X_train,Y_train)\n",
    "prd = rf_regressor.predict(X_test)\n",
    "\n",
    "rf_regressor.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Although, Linear regression is very sensitive to features treatment, other algorithms seems to adapt to the ranges of each feature. \n",
    "\n",
    "In those tests, Random Forest could adapt to features in different ranges and not totally categorized. Also, it was much better in accuracy terms than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
